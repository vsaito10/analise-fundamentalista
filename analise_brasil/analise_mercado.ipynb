{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path # noqa: F401\n",
    "from plotly.subplots import make_subplots\n",
    "import funcoes_br as f_br \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ETFs e BDRs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquivo cotações históricas\n",
    "df_cotacoes_historicas_polars = pl.read_parquet(Path('C://B3//historico-arquivos//cotacoes-historicas-b3//cotahist-parquet//cotahist_comp_2017_2025.parquet'))\n",
    "df_cotacoes_historicas_polars.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETFs\n",
    "filt_etf = (\n",
    "    (pl.col('tipo_mercado') == 10) &\n",
    "    (pl.col('codneg').str.ends_with('11'))\n",
    ")\n",
    "\n",
    "df_etfs = df_cotacoes_historicas_polars.filter(filt_etf)\n",
    "\n",
    "# Calculando o volume\n",
    "df_etfs_volume = df_etfs.group_by('codneg').agg(\n",
    "    pl.col('totneg').sum().alias('volume')\n",
    ").sort('volume', descending=True)\n",
    "\n",
    "##############################################################################\n",
    "# Lista das UNITs e fundos setoriais\n",
    "lst_unit = [\n",
    "    # UNITs - https://www.b3.com.br/pt_br/market-data-e-indices/servicos-de-dados/market-data/consultas/mercado-a-vista/units/\n",
    "    'ALUP11',\t\n",
    "    'BRBI11',\t\n",
    "    'BPAC11',\t\n",
    "    'ENGI11',\t\n",
    "    'IGTI11',\t\n",
    "    'KLBN11',\t\n",
    "    'PPLA11',\t\n",
    "    'RBNS11',\t\n",
    "    'SAPR11',\t\n",
    "    'SANB11',\n",
    "    'TAEE11',\t\n",
    "\n",
    "    # UNITs, debêntures e bônus de subscrição que não existem mais\n",
    "    'AMAR11',\n",
    "    'AMER11',\n",
    "    'APER11',\n",
    "    'AVLL11',\n",
    "    'AZEV11',\n",
    "    'AZTE11',\n",
    "    'AZUL11',\n",
    "    'BEEF11',\n",
    "    'BPHA11',\n",
    "    'BIDI11',\n",
    "    'BIOM11',\n",
    "    'BMGB11',\n",
    "    'CALI11',\n",
    "    'CGAS11',\n",
    "    'COCE11',\n",
    "    'CPLE11',\n",
    "    'CVCB11',\n",
    "    'DASA11',\n",
    "    'DMMO11',\n",
    "    'ELET11',\n",
    "    'FCCQ11',\n",
    "    'FJTA11',\n",
    "    'GFSA11',\n",
    "    'GETT11',\n",
    "    'GOLL11',\n",
    "    'GPIV11',\n",
    "    'INEP11',\n",
    "    'JBDU11',\n",
    "    'KEPL11',\n",
    "    'LIGT11',\n",
    "    'LUPA11',\n",
    "    'MBLY11',\n",
    "    'MMXM11',\n",
    "    'MODL11',\n",
    "    'MYPK11',\n",
    "    'PDGR11',\n",
    "    'PGMN11',\n",
    "    'PINE11',\n",
    "    'PSVM11',\n",
    "    'RNEW11',\n",
    "    'SEQL11',\n",
    "    'SLED11',\n",
    "    'SULA11',\n",
    "    'TIET11',\n",
    "    'VLID11',\n",
    "    'VVAR11',\n",
    "]\n",
    "\n",
    "##############################################################################\n",
    "# Lista dos FIIs da B3\n",
    "df_fiis = pd.read_csv(\n",
    "    r'C://B3//historico-arquivos//fundos-b3//fundos_listados//fiis_listados.csv',\n",
    "    sep=';',\n",
    "    engine='python',\n",
    "    encoding='latin-1',\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "# Adicionando a string '11' na coluna 'Código'\n",
    "df_fiis['Código'] = df_fiis['Código'] + '11'\n",
    "\n",
    "# Lista dos FIIs\n",
    "lst_fiis = df_fiis['Código'].to_list()\n",
    "\n",
    "# Lista de FIIs que não existem mais\n",
    "lst_fiis_deslistados = [\n",
    "    'AATH11',\n",
    "    'AEFI11',\n",
    "    'AFCR11',\n",
    "    'AFOF11',\n",
    "    'AGCX11',\n",
    "    'ALZM11',\n",
    "    'ALZT11',\n",
    "    'AQLL11',\n",
    "    'ARCT11',\n",
    "    'ASMT11',\n",
    "\n",
    "    'BAHI11', \n",
    "    'BARI11', \n",
    "    'BBPO11', \n",
    "    'BBTG11', \n",
    "    'BBVH11', \n",
    "    'BBVJ11', \n",
    "    'BCFF11', \n",
    "    'BICR11', \n",
    "    'BKOI11', \n",
    "    'BLCP11', \n",
    "    'BLMC11', \n",
    "    'BLMR11', \n",
    "    'BLUR11', \n",
    "    'BPRP11', \n",
    "    'BREV11', \n",
    "    'BRGE11', \n",
    "    'BRHY11', \n",
    "    'BRIX11', \n",
    "    'BRLA11', \n",
    "    'BTCR11', \n",
    "    'BZLI11',\n",
    "\n",
    "    'CCRF11', \n",
    "    'COPP11', \n",
    "    'CORM11', \n",
    "    'CPFF11', \n",
    "    'CVBI11',\n",
    "\n",
    "    'DMAC11',\n",
    "    'DOMC11',\n",
    "    'DRIT11',\n",
    "\n",
    "    'EQIN11',\n",
    "    'EQIA11',\n",
    "    'EVBI11',\n",
    "\n",
    "    'FEXC11', \n",
    "    'FFCI11', \n",
    "    'FLFL11', \n",
    "    'FOFT11', \n",
    "    'FRBR11', \n",
    "    'FSPM11', \n",
    "    'FVBI11',\n",
    "\n",
    "    'GALG11', \n",
    "    'GCFF11', \n",
    "    'GRLV11', \n",
    "    'GTLG11', \n",
    "    'GURB11', \n",
    "    'GWIR11',\n",
    "\n",
    "    'HBRH11', \n",
    "    'HBTT11', \n",
    "    'HGJH11', \n",
    "    'HMOC11',\n",
    "\n",
    "    'IBFF11', \n",
    "    'IDFI11', \n",
    "    'IDGR11', \n",
    "    'IFCM11', \n",
    "    'IFID11', \n",
    "    'IFIE11',\n",
    "\n",
    "    'JBFO11',\n",
    "    'JRDM11',\n",
    "    'JSLG11',\n",
    "\n",
    "    'KINP11',\n",
    "\n",
    "    'LFTT11', \n",
    "    'LGCP11', \n",
    "    'LSPA11', \n",
    "    'LUGG11',\n",
    "\n",
    "    'MALL11', \n",
    "    'MATV11', \n",
    "    'MBRF11', \n",
    "    'MCHF11', \n",
    "    'MCHY11', \n",
    "    'MFAI11', \n",
    "    'MFCR11', \n",
    "    'MGCR11', \n",
    "    'MGFF11', \n",
    "    'MGIM11', \n",
    "    'MGLG11', \n",
    "    'MINT11', \n",
    "    'MORC11', \n",
    "    'MORE11',\n",
    "\n",
    "    'NCHB11',\n",
    "    'NPAR11',\n",
    "\n",
    "    'OGHY11', \n",
    "    'ONEF11', \n",
    "    'ORPD11', \n",
    "    'OUCY11', \n",
    "    'OUFF11', \n",
    "    'OURE11',\n",
    "\n",
    "    'PLCR11',\n",
    "    'PLOG11',\n",
    "    'PURB11',\n",
    "\n",
    "    'QAMI11',\n",
    "    'QIFF11',\n",
    "    'QIRI11',\n",
    "    'QMFF11',\n",
    "\n",
    "    'RBBV11', \n",
    "    'RBCB11', \n",
    "    'RBCO11', \n",
    "    'RBED11', \n",
    "    'RBGS11', \n",
    "    'RBIV11', \n",
    "    'RBRM11', \n",
    "    'RBVO11', \n",
    "    'RDES11', \n",
    "    'RDPD11', \n",
    "    'RECX11', \n",
    "    'RNDP11', \n",
    "    'RVBI11', \n",
    "    'RZDM11',\n",
    "\n",
    "    'SAAG11', \n",
    "    'SAET11', \n",
    "    'SDIL11', \n",
    "    'SDIP11', \n",
    "    'SIGR11', \n",
    "    'SINC11', \n",
    "    'SMRT11', \n",
    "    'SNCR11', \n",
    "    'SRVD11',\n",
    "\n",
    "    'TBOF11',\n",
    "    'TFOF11', \n",
    "    'THRA11', \n",
    "    'TOUR11', \n",
    "    'TRXL11',\n",
    "\n",
    "    'UBSR11',\n",
    "\n",
    "    'VLOL11',\n",
    "    'VSEC11',\n",
    "    'VVPR11',\n",
    "    \n",
    "    'XPGA11', \n",
    "    'XPHT11', \n",
    "    'XPOM11', \n",
    "    'XPPR11', \n",
    "    'XTED11',\n",
    "\n",
    "    'YCHY11',\n",
    "]\n",
    "\n",
    "# Adiciona todos os elementos na lista\n",
    "lst_fiis.extend(lst_fiis_deslistados)\n",
    "\n",
    "##############################################################################\n",
    "# Lista dos FIAGROs da B3\n",
    "df_fiagros = pd.read_csv(\n",
    "    r'C://B3//historico-arquivos//fundos-b3//fundos_listados//fiagros_listados.csv',\n",
    "    sep=';',\n",
    "    engine='python',\n",
    "    encoding='latin-1',\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "# Adicionando a string '11' na coluna 'Código'\n",
    "df_fiagros['Código'] = df_fiagros['Código'] + '11'\n",
    "\n",
    "# Lista dos FIAGROs\n",
    "lst_fiagros = df_fiagros['Código'].to_list()\n",
    "\n",
    "# Lista de FIAGROs que não existem mais\n",
    "lst_fiagros_deslistados = [\n",
    "    'AGRX11',\n",
    "    'BRFT11',\n",
    "    'LAFI11',\n",
    "    'IAAG11'\n",
    "    'NCRA11',\n",
    "    'QAGR11',\n",
    "]\n",
    "\n",
    "# Adiciona todos os elementos na lista\n",
    "lst_fiagros.extend(lst_fiagros_deslistados)\n",
    "\n",
    "##############################################################################\n",
    "# Lista dos FIPs da B3\n",
    "df_fips = pd.read_csv(\n",
    "    r'C://B3//historico-arquivos//fundos-b3//fundos_listados//fips_listados.csv',\n",
    "    sep=';',\n",
    "    engine='python',\n",
    "    encoding='latin-1',\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "# Adicionando a string '11' na coluna 'Código'\n",
    "df_fips['Código'] = df_fips['Código'] + '11'\n",
    "\n",
    "# Lista dos FIAGROs\n",
    "lst_fips = df_fips['Código'].to_list()\n",
    "\n",
    "##############################################################################\n",
    "# Lista dos fundos setoriais da B3\n",
    "df_fisets = pd.read_csv(\n",
    "    r'C://B3//historico-arquivos//fundos-b3//fundos_listados//fiset_listados.csv',\n",
    "    sep=';',\n",
    "    engine='python',\n",
    "    encoding='latin-1',\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "# Adicionando a string '11' na coluna 'Código'\n",
    "df_fisets['Código'] = df_fisets['Código'] + '11'\n",
    "\n",
    "# Lista dos FIAGROs\n",
    "lst_fisets = df_fisets['Código'].to_list()\n",
    "\n",
    "##############################################################################\n",
    "# Lista dos fundos de infra da B3\n",
    "df_finfra = pd.read_csv(\n",
    "    r'C://B3//historico-arquivos//fundos-b3//fundos_listados//fiinfra_listados.csv',\n",
    "    sep=';',\n",
    "    engine='python',\n",
    "    encoding='latin-1',\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "# Adicionando a string '11' na coluna 'Código'\n",
    "df_finfra['Código'] = df_finfra['Código'] + '11'\n",
    "\n",
    "# Lista dos FIAGROs\n",
    "lst_finfra = df_finfra['Código'].to_list()\n",
    "\n",
    "##############################################################################\n",
    "# Conjunto dos tickers que vão ser excluídos\n",
    "set_exclusoes = set(lst_unit) | set(lst_fiis) | set(lst_fiagros) | set(lst_fips) | set(lst_fisets) | set(lst_finfra)\n",
    "lst_exclusoes = list(set_exclusoes)\n",
    "\n",
    "# Realiza a filtragem final de uma só vez\n",
    "df_etfs_volume_final = df_etfs_volume.filter(\n",
    "    ~pl.col('codneg').is_in(lst_exclusoes)\n",
    ")\n",
    "\n",
    "print('='*40)\n",
    "print(f'Total de ETFs disponíveis: {len(df_etfs_volume_final)}')\n",
    "print('='*40)\n",
    "\n",
    "df_etfs_volume_final[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDRs\n",
    "filt = (\n",
    "    (pl.col('tipo_mercado') == 10) &            \n",
    "    (pl.col('codneg').str.contains('34'))                       \n",
    ")\n",
    "\n",
    "df_bdrs = df_cotacoes_historicas_polars.filter(filt)\n",
    "\n",
    "# Calculando o volume\n",
    "df_bdrs_volume = df_bdrs.group_by('codneg').agg(\n",
    "    pl.col('totneg').sum().alias('volume')\n",
    ").sort('volume', descending=True)\n",
    "\n",
    "print('='*40)\n",
    "print(f'Total de BDRs disponíveis: {len(df_bdrs_volume)}')\n",
    "print('='*40)\n",
    "\n",
    "df_bdrs_volume[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDRs de ETFs\n",
    "filt = (\n",
    "    (pl.col('tipo_mercado') == 10) &            \n",
    "    (pl.col('codneg').str.contains('39'))                       \n",
    ")\n",
    "\n",
    "df_bdrs_etfs = df_cotacoes_historicas_polars.filter(filt)\n",
    "\n",
    "# Calculando o volume\n",
    "df_bdrs_etfs_volume = df_bdrs_etfs.group_by('codneg').agg(\n",
    "    pl.col('totneg').sum().alias('volume')\n",
    ").sort('volume', descending=True)\n",
    "\n",
    "print('='*40)\n",
    "print(f'Total de BDRs de ETFs disponíveis: {len(df_bdrs_etfs_volume)}')\n",
    "print('='*40)\n",
    "\n",
    "df_bdrs_etfs_volume[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análise dos Anos Eleitorais e de Crises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anos Eleitorais - BRASIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados do papel em específico\n",
    "ticker = '^BVSP'\n",
    "ativo = yf.download(ticker, start='1995-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Resetando o index do df\n",
    "ativo = ativo.reset_index()  \n",
    "\n",
    "# Renomeando as colunas para remover o MultiIndex\n",
    "ativo.columns = ['Date', 'Close']  \n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "ativo = ativo.set_index('Date')\n",
    "\n",
    "# Fazendo uma copia do df ativo\n",
    "df = ativo.copy()\n",
    "\n",
    "# Cria uma coluna para o ano de cada dia\n",
    "df['ano'] = df.index.year \n",
    "\n",
    "# Cria uma coluna para o nº inteiro de cada dia -> 1 = primeiro dia do ano ... 365 = último dia do ano\n",
    "df['dia_do_ano'] = df.index.dayofyear \n",
    "\n",
    "# Criando a tabela pivot\n",
    "tabela = df.pivot(index='dia_do_ano', columns='ano', values='Close')\n",
    "\n",
    "# Utilizo o método 'bfill' para completar os NaN\n",
    "tabela_final = tabela.bfill()\n",
    "\n",
    "# Tranformo a tabela dos preços de fechamento para a variação percentual do dia\n",
    "tabela_final = (tabela_final / tabela_final.iloc[0]) - 1\n",
    "\n",
    "tabela_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o gráfico dos anos eleitorais\n",
    "anos_eleitorais = [\n",
    "    1998, 2002, 2006, 2010, \n",
    "    2014, 2018, 2022\n",
    "]\n",
    "\n",
    "fig = px.line(tabela_final[anos_eleitorais], \n",
    "              height=600, \n",
    "              width=800, \n",
    "              template='plotly_dark',\n",
    "              title='Performance IBOVESPA em anos eleitorais',\n",
    "              labels={'value':'retorno'})\n",
    "\n",
    "# Mudando a espessura da linha do gráfico\n",
    "fig.update_traces(line=dict(width=1))\n",
    "\n",
    "# Criando duas linhas verticais no início e fim de Outubro\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-01').dayofyear)\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-31').dayofyear)\n",
    "\n",
    "# Criando uma linha horizontal\n",
    "fig.add_hline(y=0, line=dict(color='red', width=1))\n",
    "\n",
    "# Formatando o eixo y do gráfico para aparecer em %\n",
    "fig.layout.yaxis.tickformat = '.0%'\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno mensal de Outubro dos anos eleitorais\n",
    "lista_ret_out = [round((((df.loc[f'{ano}-10', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno mensal de Outubro até o final do ano eleitoral\n",
    "lista_ret_out_dez = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1 )*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno anual dos anos eleitorais\n",
    "lista_ret_ano = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-01', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "df_ret_eleicao = pd.DataFrame(list(zip(lista_ret_out, lista_ret_out_dez, lista_ret_ano)), \n",
    "                              columns=['retorno_out', 'retorno_out_dez', 'retorno_anual'], \n",
    "                              index=anos_eleitorais\n",
    ")\n",
    "df_ret_eleicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibov = yf.download('^BVSP', start='1998-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Plotando o 1º e 2º dos anos eleitorais\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_ibov.index,\n",
    "    y=df_ibov\n",
    "))\n",
    "\n",
    "# Adicionando linhas verticais nas datas do 1º e 2º turno das eleições\n",
    "fig.add_vline(x='1998-10-04', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (FHC x Lula x Ciro Gomes - turno único)\n",
    "\n",
    "fig.add_vline(x='2002-10-06', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Serra)\n",
    "fig.add_vline(x='2002-10-27', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2006-10-01', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Alckmin)\n",
    "fig.add_vline(x='2006-10-29', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2010-10-03', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Dilma x Serra)\n",
    "fig.add_vline(x='2010-10-31', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2014-10-05', line_width=1, line_dash='dash', line_color='black') # 1º turno 2014 (Dilma x Aécio)\n",
    "fig.add_vline(x='2014-10-26', line_width=1, line_dash='dash', line_color='red') # 2º turno 2014 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2018-10-07', line_width=1, line_dash='dash', line_color='black') # 1º turno 2018 (Haddad x Bolsonaro)\n",
    "fig.add_vline(x='2018-10-28', line_width=1, line_dash='dash', line_color='red') # 2º turno 2018 (Bolsonaro ganhador)\n",
    "\n",
    "fig.add_vline(x='2022-10-02', line_width=1, line_dash='dash', line_color='black') # 1º turno 2022 (Lula x Bolsonaro)\n",
    "fig.add_vline(x='2022-10-30', line_width=1, line_dash='dash', line_color='red') # 2º turno 2022 (Lula ganhador)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='IBOVESPA - 1º e 2º turno das eleições',\n",
    "    template='seaborn'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas dos 1º e 2º turnos das eleições\n",
    "lst_datas_turnos = [\n",
    "    ('2002-10-06', '2002-10-27'),\n",
    "    ('2006-10-01', '2006-10-29'),\n",
    "    ('2010-10-03', '2010-10-31'),\n",
    "    ('2014-10-05', '2014-10-26'),\n",
    "    ('2018-10-07', '2018-10-28'),\n",
    "    ('2022-10-02', '2022-10-30')\n",
    "]\n",
    "\n",
    "# Lista das segundas-feiras pós cada turno\n",
    "lst_segunda_feira_pos_1_turno = []\n",
    "lst_segunda_feira_pos_2_turno = []\n",
    "\n",
    "for primeiro_turno, segundo_turno in lst_datas_turnos:\n",
    "    # Calculando a segunda-feira após o 1º turno\n",
    "    data_1_turno = datetime.strptime(primeiro_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_1_turno = (data_1_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_1_turno.append(segunda_feira_pos_1_turno)\n",
    "\n",
    "    # Calculando a segunda-feira após o 2º turno\n",
    "    data_2_turno = datetime.strptime(segundo_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_2_turno = (data_2_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_2_turno.append(segunda_feira_pos_2_turno)\n",
    "\n",
    "# Variação percentual entre o 1º e 2º turno\n",
    "anos_eleicoes = [2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "dict_pct_changes_turnos = {}\n",
    "\n",
    "for data_1, data_2, ano in zip(lst_segunda_feira_pos_1_turno, lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_turno = round(((df_ibov.loc[data_2] / df_ibov.loc[data_1]) - 1) * 100, 2)\n",
    "    dict_pct_changes_turnos[ano] = pct_change_turno\n",
    "\n",
    "# Transforando em um df\n",
    "df_pct_changes_turnos = pd.DataFrame.from_dict(dict_pct_changes_turnos, orient='index', columns=['pct_change_turnos'])\n",
    "df_pct_changes_turnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 1º turno (segunda-feira pós 1º turno)\n",
    "dict_meses_1_turno = {}\n",
    "\n",
    "for primeiro_turno, ano in zip(lst_segunda_feira_pos_1_turno, anos_eleicoes):\n",
    "    pct_change_jan_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_1_turno = round(((df_ibov.loc[primeiro_turno] / df_ibov[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_1_turno[ano] = {\n",
    "        'Jan': pct_change_jan_1_turno,\n",
    "        'Feb': pct_change_feb_1_turno,\n",
    "        'Mar': pct_change_mar_1_turno,\n",
    "        'Apr': pct_change_apr_1_turno,\n",
    "        'May': pct_change_may_1_turno,\n",
    "        'Jun': pct_change_jun_1_turno,\n",
    "        'Jul': pct_change_jul_1_turno,\n",
    "        'Aug': pct_change_aug_1_turno,\n",
    "        'Sep': pct_change_sep_1_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_1_turno = pd.DataFrame(dict_meses_1_turno).T\n",
    "df_pct_change_meses_1_turno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 2º turno (segunda-feira pós 2º turno)\n",
    "dict_meses_2_turno = {}\n",
    "\n",
    "for segundo_turno, ano in zip(lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_jan_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_2_turno = round(((df_ibov.loc[segundo_turno] / df_ibov[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_2_turno[ano] = {\n",
    "        'Jan': pct_change_jan_2_turno,\n",
    "        'Feb': pct_change_feb_2_turno,\n",
    "        'Mar': pct_change_mar_2_turno,\n",
    "        'Apr': pct_change_apr_2_turno,\n",
    "        'May': pct_change_may_2_turno,\n",
    "        'Jun': pct_change_jun_2_turno,\n",
    "        'Jul': pct_change_jul_2_turno,\n",
    "        'Aug': pct_change_aug_2_turno,\n",
    "        'Sep': pct_change_sep_2_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_2_turno = pd.DataFrame(dict_meses_2_turno).T\n",
    "df_pct_change_meses_2_turno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno diário\n",
    "ret_diario = df_ibov.pct_change()\n",
    "\n",
    "# Criando uma lista com os drawdowns de cada ano eleitoral\n",
    "lista_drawdowns_eleitorais = [f_br.drawdown(ret_diario.loc[f'{ano}']) for ano in anos_eleitorais]\n",
    "\n",
    "df_drawdowns_eleitorais= pd.DataFrame(lista_drawdowns_eleitorais, columns=['drawdown_ano_eleitoral'], index=anos_eleitorais)\n",
    "df_drawdowns_eleitorais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno logarítmico\n",
    "ret_log = np.log(df_ibov / df_ibov.shift(1))\n",
    "\n",
    "# Calculando a volatilidade anualizada dos anos eleitorais\n",
    "lista_vol_anual = [(ret_log.loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_eleitorais]\n",
    "\n",
    "df_vol_anual = pd.DataFrame(lista_vol_anual, columns=['vol_anual'], index=anos_eleitorais)\n",
    "df_vol_anual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PETR4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados do papel em específico\n",
    "ticker = 'PETR4.SA'\n",
    "petr = yf.download(ticker, start='1995-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Resetando o index do df\n",
    "petr = petr.reset_index()  \n",
    "\n",
    "# Renomeando as colunas para remover o MultiIndex\n",
    "petr.columns = ['Date', 'Close']  \n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "petr = petr.set_index('Date')\n",
    "\n",
    "# Fazendo uma copia do df ativo\n",
    "df = petr.copy()\n",
    "\n",
    "# Cria uma coluna para o ano de cada dia\n",
    "df['ano'] = df.index.year \n",
    "\n",
    "# Cria uma coluna para o nº inteiro de cada dia -> 1 = primeiro dia do ano ... 365 = último dia do ano\n",
    "df['dia_do_ano'] = df.index.dayofyear \n",
    "\n",
    "# Criando a tabela pivot\n",
    "df_pivot = df.pivot(index='dia_do_ano', columns='ano', values='Close')\n",
    "\n",
    "# Utilizo o método 'bfill' para completar os NaN\n",
    "df_pivot_petr = df_pivot.bfill()\n",
    "\n",
    "# Tranformo a tabela dos preços de fechamento para a variação percentual do dia\n",
    "df_pivot_petr = (df_pivot_petr / df_pivot_petr.iloc[0]) - 1\n",
    "\n",
    "df_pivot_petr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o gráfico dos anos eleitorais\n",
    "anos_eleitorais = [2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "fig = px.line(df_pivot_petr[anos_eleitorais], \n",
    "              height=600, \n",
    "              width=800, \n",
    "              template='plotly_dark',\n",
    "              title='Performance PETR4 em anos eleitorais',\n",
    "              labels={'value':'retorno'})\n",
    "\n",
    "# Mudando a espessura da linha do gráfico\n",
    "fig.update_traces(line=dict(width=1))\n",
    "\n",
    "# Criando duas linhas verticais no início e fim de Outubro\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-01').dayofyear)\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-31').dayofyear)\n",
    "\n",
    "# Criando uma linha horizontal\n",
    "fig.add_hline(y=0, line=dict(color='red', width=1))\n",
    "\n",
    "# Formatando o eixo y do gráfico para aparecer em %\n",
    "fig.layout.yaxis.tickformat = '.0%'\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno mensal de Outubro dos anos eleitorais\n",
    "lista_ret_out = [round((((df.loc[f'{ano}-10', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno mensal de Outubro até o final do ano eleitoral\n",
    "lista_ret_out_dez = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1 )*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno anual dos anos eleitorais\n",
    "lista_ret_ano = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-01', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "df_ret_eleicao_petr = pd.DataFrame(list(zip(lista_ret_out, lista_ret_out_dez, lista_ret_ano)), \n",
    "                              columns=['retorno_out', 'retorno_out_dez', 'retorno_anual'], \n",
    "                              index=anos_eleitorais\n",
    ")\n",
    "df_ret_eleicao_petr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_petr = yf.download('PETR4.SA', start='2002-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Plotando o 1º e 2º dos anos eleitorais\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_petr.index,\n",
    "    y=df_petr\n",
    "))\n",
    "\n",
    "# Adicionando linhas verticais nas datas do 1º e 2º turno das eleições\n",
    "fig.add_vline(x='2002-10-06', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Serra)\n",
    "fig.add_vline(x='2002-10-27', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2006-10-01', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Alckmin)\n",
    "fig.add_vline(x='2006-10-29', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2010-10-03', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Dilma x Serra)\n",
    "fig.add_vline(x='2010-10-31', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2014-10-05', line_width=1, line_dash='dash', line_color='black') # 1º turno 2014 (Dilma x Aécio)\n",
    "fig.add_vline(x='2014-10-26', line_width=1, line_dash='dash', line_color='red') # 2º turno 2014 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2018-10-07', line_width=1, line_dash='dash', line_color='black') # 1º turno 2018 (Haddad x Bolsonaro)\n",
    "fig.add_vline(x='2018-10-28', line_width=1, line_dash='dash', line_color='red') # 2º turno 2018 (Bolsonaro ganhador)\n",
    "\n",
    "fig.add_vline(x='2022-10-02', line_width=1, line_dash='dash', line_color='black') # 1º turno 2022 (Lula x Bolsonaro)\n",
    "fig.add_vline(x='2022-10-30', line_width=1, line_dash='dash', line_color='red') # 2º turno 2022 (Lula ganhador)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='PETR4 - 1º e 2º turno das eleições',\n",
    "    template='seaborn'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas dos 1º e 2º turnos das eleições\n",
    "lst_datas_turnos = [\n",
    "    ('2002-10-06', '2002-10-27'),\n",
    "    ('2006-10-01', '2006-10-29'),\n",
    "    ('2010-10-03', '2010-10-31'),\n",
    "    ('2014-10-05', '2014-10-26'),\n",
    "    ('2018-10-07', '2018-10-28'),\n",
    "    ('2022-10-02', '2022-10-30')\n",
    "]\n",
    "\n",
    "# Lista das segundas-feiras pós cada turno\n",
    "lst_segunda_feira_pos_1_turno = []\n",
    "lst_segunda_feira_pos_2_turno = []\n",
    "\n",
    "for primeiro_turno, segundo_turno in lst_datas_turnos:\n",
    "    # Calculando a segunda-feira após o 1º turno\n",
    "    data_1_turno = datetime.strptime(primeiro_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_1_turno = (data_1_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_1_turno.append(segunda_feira_pos_1_turno)\n",
    "\n",
    "    # Calculando a segunda-feira após o 2º turno\n",
    "    data_2_turno = datetime.strptime(segundo_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_2_turno = (data_2_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_2_turno.append(segunda_feira_pos_2_turno)\n",
    "\n",
    "# Variação percentual entre o 1º e 2º turno\n",
    "anos_eleicoes = [2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "dict_pct_changes_turnos = {}\n",
    "\n",
    "for data_1, data_2, ano in zip(lst_segunda_feira_pos_1_turno, lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_turno = round(((df_petr.loc[data_2] / df_petr.loc[data_1]) - 1) * 100, 2)\n",
    "    dict_pct_changes_turnos[ano] = pct_change_turno\n",
    "\n",
    "# Transforando em um df\n",
    "df_pct_changes_turnos_petr = pd.DataFrame.from_dict(dict_pct_changes_turnos, orient='index', columns=['pct_change_turnos'])\n",
    "df_pct_changes_turnos_petr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 1º turno (segunda-feira pós 1º turno)\n",
    "dict_meses_1_turno = {}\n",
    "\n",
    "for primeiro_turno, ano in zip(lst_segunda_feira_pos_1_turno, anos_eleicoes):\n",
    "    pct_change_jan_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_1_turno = round(((df_petr.loc[primeiro_turno] / df_petr[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_1_turno[ano] = {\n",
    "        'Jan': pct_change_jan_1_turno,\n",
    "        'Feb': pct_change_feb_1_turno,\n",
    "        'Mar': pct_change_mar_1_turno,\n",
    "        'Apr': pct_change_apr_1_turno,\n",
    "        'May': pct_change_may_1_turno,\n",
    "        'Jun': pct_change_jun_1_turno,\n",
    "        'Jul': pct_change_jul_1_turno,\n",
    "        'Aug': pct_change_aug_1_turno,\n",
    "        'Sep': pct_change_sep_1_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_1_turno_petr = pd.DataFrame(dict_meses_1_turno).T\n",
    "df_pct_change_meses_1_turno_petr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 2º turno (segunda-feira pós 2º turno)\n",
    "dict_meses_2_turno = {}\n",
    "\n",
    "for segundo_turno, ano in zip(lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_jan_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_2_turno = round(((df_petr.loc[segundo_turno] / df_petr[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_2_turno[ano] = {\n",
    "        'Jan': pct_change_jan_2_turno,\n",
    "        'Feb': pct_change_feb_2_turno,\n",
    "        'Mar': pct_change_mar_2_turno,\n",
    "        'Apr': pct_change_apr_2_turno,\n",
    "        'May': pct_change_may_2_turno,\n",
    "        'Jun': pct_change_jun_2_turno,\n",
    "        'Jul': pct_change_jul_2_turno,\n",
    "        'Aug': pct_change_aug_2_turno,\n",
    "        'Sep': pct_change_sep_2_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_2_turno_petr = pd.DataFrame(dict_meses_2_turno).T\n",
    "df_pct_change_meses_2_turno_petr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno diário\n",
    "ret_diario_petr = df_petr.pct_change()\n",
    "\n",
    "# Criando uma lista com os drawdowns de cada ano eleitoral\n",
    "lista_drawdowns_eleitorais_petr = [f_br.drawdown(ret_diario_petr.loc[f'{ano}']) for ano in anos_eleitorais]\n",
    "\n",
    "df_drawdowns_eleitorais_petr = pd.DataFrame(lista_drawdowns_eleitorais_petr, columns=['drawdown_ano_eleitoral'], index=anos_eleitorais)\n",
    "df_drawdowns_eleitorais_petr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno logarítmico\n",
    "ret_log_petr = np.log(df_petr / df_petr.shift(1))\n",
    "\n",
    "# Calculando a volatilidade anualizada dos anos eleitorais\n",
    "lista_vol_anual_petr = [(ret_log_petr.loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_eleitorais]\n",
    "\n",
    "df_vol_anual_petr = pd.DataFrame(lista_vol_anual_petr, columns=['vol_anual'], index=anos_eleitorais)\n",
    "df_vol_anual_petr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados do papel em específico\n",
    "ticker = 'VALE3.SA'\n",
    "vale = yf.download(ticker, start='1995-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Resetando o index do df\n",
    "vale = vale.reset_index()  \n",
    "\n",
    "# Renomeando as colunas para remover o MultiIndex\n",
    "vale.columns = ['Date', 'Close']  \n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "vale = vale.set_index('Date')\n",
    "\n",
    "# Fazendo uma copia do df ativo\n",
    "df = vale.copy()\n",
    "\n",
    "# Cria uma coluna para o ano de cada dia\n",
    "df['ano'] = df.index.year \n",
    "\n",
    "# Cria uma coluna para o nº inteiro de cada dia -> 1 = primeiro dia do ano ... 365 = último dia do ano\n",
    "df['dia_do_ano'] = df.index.dayofyear \n",
    "\n",
    "# Criando a tabela pivot\n",
    "df_pivot = df.pivot(index='dia_do_ano', columns='ano', values='Close')\n",
    "\n",
    "# Utilizo o método 'bfill' para completar os NaN\n",
    "df_pivot_vale = df_pivot.bfill()\n",
    "\n",
    "# Tranformo a tabela dos preços de fechamento para a variação percentual do dia\n",
    "df_pivot_vale = (df_pivot_vale / df_pivot_vale.iloc[0]) - 1\n",
    "\n",
    "df_pivot_vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o gráfico dos anos eleitorais\n",
    "anos_eleitorais = [2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "fig = px.line(df_pivot_vale[anos_eleitorais], \n",
    "              height=600, \n",
    "              width=800, \n",
    "              template='plotly_dark',\n",
    "              title='Performance VALE3 em anos eleitorais',\n",
    "              labels={'value':'retorno'})\n",
    "\n",
    "# Mudando a espessura da linha do gráfico\n",
    "fig.update_traces(line=dict(width=1))\n",
    "\n",
    "# Criando duas linhas verticais no início e fim de Outubro\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-01').dayofyear)\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-31').dayofyear)\n",
    "\n",
    "# Criando uma linha horizontal\n",
    "fig.add_hline(y=0, line=dict(color='red', width=1))\n",
    "\n",
    "# Formatando o eixo y do gráfico para aparecer em %\n",
    "fig.layout.yaxis.tickformat = '.0%'\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno mensal de Outubro dos anos eleitorais\n",
    "lista_ret_out = [round((((df.loc[f'{ano}-10', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno mensal de Outubro até o final do ano eleitoral\n",
    "lista_ret_out_dez = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1 )*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno anual dos anos eleitorais\n",
    "lista_ret_ano = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-01', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "df_ret_eleicao_vale = pd.DataFrame(list(zip(lista_ret_out, lista_ret_out_dez, lista_ret_ano)), \n",
    "                              columns=['retorno_out', 'retorno_out_dez', 'retorno_anual'], \n",
    "                              index=anos_eleitorais\n",
    ")\n",
    "\n",
    "df_ret_eleicao_vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vale = yf.download('VALE3.SA', start='2002-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Plotando o 1º e 2º dos anos eleitorais\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_vale.index,\n",
    "    y=df_vale\n",
    "))\n",
    "\n",
    "# Adicionando linhas verticais nas datas do 1º e 2º turno das eleições\n",
    "fig.add_vline(x='2002-10-06', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Serra)\n",
    "fig.add_vline(x='2002-10-27', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2006-10-01', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Alckmin)\n",
    "fig.add_vline(x='2006-10-29', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2010-10-03', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Dilma x Serra)\n",
    "fig.add_vline(x='2010-10-31', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2014-10-05', line_width=1, line_dash='dash', line_color='black') # 1º turno 2014 (Dilma x Aécio)\n",
    "fig.add_vline(x='2014-10-26', line_width=1, line_dash='dash', line_color='red') # 2º turno 2014 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2018-10-07', line_width=1, line_dash='dash', line_color='black') # 1º turno 2018 (Haddad x Bolsonaro)\n",
    "fig.add_vline(x='2018-10-28', line_width=1, line_dash='dash', line_color='red') # 2º turno 2018 (Bolsonaro ganhador)\n",
    "\n",
    "fig.add_vline(x='2022-10-02', line_width=1, line_dash='dash', line_color='black') # 1º turno 2022 (Lula x Bolsonaro)\n",
    "fig.add_vline(x='2022-10-30', line_width=1, line_dash='dash', line_color='red') # 2º turno 2022 (Lula ganhador)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='VALE3 - 1º e 2º turno das eleições',\n",
    "    template='seaborn'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas dos 1º e 2º turnos das eleições\n",
    "lst_datas_turnos = [\n",
    "    ('2002-10-06', '2002-10-27'),\n",
    "    ('2006-10-01', '2006-10-29'),\n",
    "    ('2010-10-03', '2010-10-31'),\n",
    "    ('2014-10-05', '2014-10-26'),\n",
    "    ('2018-10-07', '2018-10-28'),\n",
    "    ('2022-10-02', '2022-10-30')\n",
    "]\n",
    "\n",
    "# Lista das segundas-feiras pós cada turno\n",
    "lst_segunda_feira_pos_1_turno = []\n",
    "lst_segunda_feira_pos_2_turno = []\n",
    "\n",
    "for primeiro_turno, segundo_turno in lst_datas_turnos:\n",
    "    # Calculando a segunda-feira após o 1º turno\n",
    "    data_1_turno = datetime.strptime(primeiro_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_1_turno = (data_1_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_1_turno.append(segunda_feira_pos_1_turno)\n",
    "\n",
    "    # Calculando a segunda-feira após o 2º turno\n",
    "    data_2_turno = datetime.strptime(segundo_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_2_turno = (data_2_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_2_turno.append(segunda_feira_pos_2_turno)\n",
    "\n",
    "# Variação percentual entre o 1º e 2º turno\n",
    "anos_eleicoes = [2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "dict_pct_changes_turnos = {}\n",
    "\n",
    "for data_1, data_2, ano in zip(lst_segunda_feira_pos_1_turno, lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_turno = round(((df_vale.loc[data_2] / df_vale.loc[data_1]) - 1) * 100, 2)\n",
    "    dict_pct_changes_turnos[ano] = pct_change_turno\n",
    "\n",
    "# Transforando em um df\n",
    "df_pct_changes_turnos_vale = pd.DataFrame.from_dict(dict_pct_changes_turnos, orient='index', columns=['pct_change_turnos'])\n",
    "df_pct_changes_turnos_vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 1º turno (segunda-feira pós 1º turno)\n",
    "dict_meses_1_turno = {}\n",
    "\n",
    "for primeiro_turno, ano in zip(lst_segunda_feira_pos_1_turno, anos_eleicoes):\n",
    "    pct_change_jan_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_1_turno = round(((df_vale.loc[primeiro_turno] / df_vale[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_1_turno[ano] = {\n",
    "        'Jan': pct_change_jan_1_turno,\n",
    "        'Feb': pct_change_feb_1_turno,\n",
    "        'Mar': pct_change_mar_1_turno,\n",
    "        'Apr': pct_change_apr_1_turno,\n",
    "        'May': pct_change_may_1_turno,\n",
    "        'Jun': pct_change_jun_1_turno,\n",
    "        'Jul': pct_change_jul_1_turno,\n",
    "        'Aug': pct_change_aug_1_turno,\n",
    "        'Sep': pct_change_sep_1_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_1_turno_vale = pd.DataFrame(dict_meses_1_turno).T\n",
    "df_pct_change_meses_1_turno_vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 2º turno (segunda-feira pós 2º turno)\n",
    "dict_meses_2_turno = {}\n",
    "\n",
    "for segundo_turno, ano in zip(lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_jan_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_2_turno = round(((df_vale.loc[segundo_turno] / df_vale[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_2_turno[ano] = {\n",
    "        'Jan': pct_change_jan_2_turno,\n",
    "        'Feb': pct_change_feb_2_turno,\n",
    "        'Mar': pct_change_mar_2_turno,\n",
    "        'Apr': pct_change_apr_2_turno,\n",
    "        'May': pct_change_may_2_turno,\n",
    "        'Jun': pct_change_jun_2_turno,\n",
    "        'Jul': pct_change_jul_2_turno,\n",
    "        'Aug': pct_change_aug_2_turno,\n",
    "        'Sep': pct_change_sep_2_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_2_turno_vale = pd.DataFrame(dict_meses_2_turno).T\n",
    "df_pct_change_meses_2_turno_vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno diário\n",
    "ret_diario_vale = df_vale.pct_change()\n",
    "\n",
    "# Criando uma lista com os drawdowns de cada ano eleitoral\n",
    "lista_drawdowns_eleitorais_vale = [f_br.drawdown(ret_diario_vale.loc[f'{ano}']) for ano in anos_eleitorais]\n",
    "\n",
    "df_drawdowns_eleitorais_vale = pd.DataFrame(lista_drawdowns_eleitorais_vale, columns=['drawdown_ano_eleitoral'], index=anos_eleitorais)\n",
    "df_drawdowns_eleitorais_vale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno logarítmico\n",
    "ret_log_vale = np.log(df_vale / df_vale.shift(1))\n",
    "\n",
    "# Calculando a volatilidade anualizada dos anos eleitorais\n",
    "lista_vol_anual_vale = [(ret_log_vale.loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_eleitorais]\n",
    "\n",
    "df_vol_anual_vale = pd.DataFrame(lista_vol_anual_vale, columns=['vol_anual'], index=anos_eleitorais)\n",
    "df_vol_anual_vale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BBAS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados do papel em específico\n",
    "ticker = 'BBAS3.SA'\n",
    "bbas = yf.download(ticker, start='1995-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Resetando o index do df\n",
    "bbas = bbas.reset_index()  \n",
    "\n",
    "# Renomeando as colunas para remover o MultiIndex\n",
    "bbas.columns = ['Date', 'Close']  \n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "bbas = bbas.set_index('Date')\n",
    "\n",
    "# Fazendo uma copia do df ativo\n",
    "df = bbas.copy()\n",
    "\n",
    "# Cria uma coluna para o ano de cada dia\n",
    "df['ano'] = df.index.year \n",
    "\n",
    "# Cria uma coluna para o nº inteiro de cada dia -> 1 = primeiro dia do ano ... 365 = último dia do ano\n",
    "df['dia_do_ano'] = df.index.dayofyear \n",
    "\n",
    "# Criando a tabela pivot\n",
    "df_pivot = df.pivot(index='dia_do_ano', columns='ano', values='Close')\n",
    "\n",
    "# Utilizo o método 'bfill' para completar os NaN\n",
    "df_pivot_bbas = df_pivot.bfill()\n",
    "\n",
    "# Tranformo a tabela dos preços de fechamento para a variação percentual do dia\n",
    "df_pivot_bbas = (df_pivot_bbas / df_pivot_bbas.iloc[0]) - 1\n",
    "\n",
    "df_pivot_bbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o gráfico dos anos eleitorais\n",
    "anos_eleitorais = [2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "fig = px.line(df_pivot_bbas[anos_eleitorais], \n",
    "              height=600, \n",
    "              width=800, \n",
    "              template='plotly_dark',\n",
    "              title='Performance BBAS3 em anos eleitorais',\n",
    "              labels={'value':'retorno'})\n",
    "\n",
    "# Mudando a espessura da linha do gráfico\n",
    "fig.update_traces(line=dict(width=1))\n",
    "\n",
    "# Criando duas linhas verticais no início e fim de Outubro\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-01').dayofyear)\n",
    "fig.add_vline(x=pd.to_datetime('2022-10-31').dayofyear)\n",
    "\n",
    "# Criando uma linha horizontal\n",
    "fig.add_hline(y=0, line=dict(color='red', width=1))\n",
    "\n",
    "# Formatando o eixo y do gráfico para aparecer em %\n",
    "fig.layout.yaxis.tickformat = '.0%'\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno mensal de Outubro dos anos eleitorais\n",
    "lista_ret_out = [round((((df.loc[f'{ano}-10', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno mensal de Outubro até o final do ano eleitoral\n",
    "lista_ret_out_dez = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-10', 'Close'].iloc[0]))-1 )*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "# Calculando o retorno anual dos anos eleitorais\n",
    "lista_ret_ano = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-01', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_eleitorais]\n",
    "\n",
    "df_ret_eleicao_bbas = pd.DataFrame(list(zip(lista_ret_out, lista_ret_out_dez, lista_ret_ano)), \n",
    "                              columns=['retorno_out', 'retorno_out_dez', 'retorno_anual'], \n",
    "                              index=anos_eleitorais\n",
    ")\n",
    "\n",
    "df_ret_eleicao_bbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbas = yf.download('BBAS3.SA', start='2002-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Plotando o 1º e 2º dos anos eleitorais\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_bbas.index,\n",
    "    y=df_bbas\n",
    "))\n",
    "\n",
    "# Adicionando linhas verticais nas datas do 1º e 2º turno das eleições\n",
    "fig.add_vline(x='2002-10-06', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Serra)\n",
    "fig.add_vline(x='2002-10-27', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2006-10-01', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Lula x Alckmin)\n",
    "fig.add_vline(x='2006-10-29', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Lula ganhador)\n",
    "\n",
    "fig.add_vline(x='2010-10-03', line_width=1, line_dash='dash', line_color='black') # 1º turno 2010 (Dilma x Serra)\n",
    "fig.add_vline(x='2010-10-31', line_width=1, line_dash='dash', line_color='red') # 2º turno 2010 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2014-10-05', line_width=1, line_dash='dash', line_color='black') # 1º turno 2014 (Dilma x Aécio)\n",
    "fig.add_vline(x='2014-10-26', line_width=1, line_dash='dash', line_color='red') # 2º turno 2014 (Dilma ganhadora)\n",
    "\n",
    "fig.add_vline(x='2018-10-07', line_width=1, line_dash='dash', line_color='black') # 1º turno 2018 (Haddad x Bolsonaro)\n",
    "fig.add_vline(x='2018-10-28', line_width=1, line_dash='dash', line_color='red') # 2º turno 2018 (Bolsonaro ganhador)\n",
    "\n",
    "fig.add_vline(x='2022-10-02', line_width=1, line_dash='dash', line_color='black') # 1º turno 2022 (Lula x Bolsonaro)\n",
    "fig.add_vline(x='2022-10-30', line_width=1, line_dash='dash', line_color='red') # 2º turno 2022 (Lula ganhador)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='BBAS3 - 1º e 2º turno das eleições',\n",
    "    template='seaborn'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas dos 1º e 2º turnos das eleições\n",
    "lst_datas_turnos = [\n",
    "    ('2002-10-06', '2002-10-27'),\n",
    "    ('2006-10-01', '2006-10-29'),\n",
    "    ('2010-10-03', '2010-10-31'),\n",
    "    ('2014-10-05', '2014-10-26'),\n",
    "    ('2018-10-07', '2018-10-28'),\n",
    "    ('2022-10-02', '2022-10-30')\n",
    "]\n",
    "\n",
    "# Lista das segundas-feiras pós cada turno\n",
    "lst_segunda_feira_pos_1_turno = []\n",
    "lst_segunda_feira_pos_2_turno = []\n",
    "\n",
    "for primeiro_turno, segundo_turno in lst_datas_turnos:\n",
    "    # Calculando a segunda-feira após o 1º turno\n",
    "    data_1_turno = datetime.strptime(primeiro_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_1_turno = (data_1_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_1_turno.append(segunda_feira_pos_1_turno)\n",
    "\n",
    "    # Calculando a segunda-feira após o 2º turno\n",
    "    data_2_turno = datetime.strptime(segundo_turno, '%Y-%m-%d')\n",
    "    segunda_feira_pos_2_turno = (data_2_turno + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    lst_segunda_feira_pos_2_turno.append(segunda_feira_pos_2_turno)\n",
    "\n",
    "# Variação percentual entre o 1º e 2º turno\n",
    "anos_eleicoes = [2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "dict_pct_changes_turnos = {}\n",
    "\n",
    "for data_1, data_2, ano in zip(lst_segunda_feira_pos_1_turno, lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_turno = round(((df_bbas.loc[data_2] / df_bbas.loc[data_1]) - 1) * 100, 2)\n",
    "    dict_pct_changes_turnos[ano] = pct_change_turno\n",
    "\n",
    "# Transforando em um df\n",
    "df_pct_changes_turnos_bbas = pd.DataFrame.from_dict(dict_pct_changes_turnos, orient='index', columns=['pct_change_turnos'])\n",
    "df_pct_changes_turnos_bbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 1º turno (segunda-feira pós 1º turno)\n",
    "dict_meses_1_turno = {}\n",
    "\n",
    "for primeiro_turno, ano in zip(lst_segunda_feira_pos_1_turno, anos_eleicoes):\n",
    "    pct_change_jan_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_1_turno = round(((df_bbas.loc[primeiro_turno] / df_bbas[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_1_turno[ano] = {\n",
    "        'Jan': pct_change_jan_1_turno,\n",
    "        'Feb': pct_change_feb_1_turno,\n",
    "        'Mar': pct_change_mar_1_turno,\n",
    "        'Apr': pct_change_apr_1_turno,\n",
    "        'May': pct_change_may_1_turno,\n",
    "        'Jun': pct_change_jun_1_turno,\n",
    "        'Jul': pct_change_jul_1_turno,\n",
    "        'Aug': pct_change_aug_1_turno,\n",
    "        'Sep': pct_change_sep_1_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_1_turno_bbas = pd.DataFrame(dict_meses_1_turno).T\n",
    "df_pct_change_meses_1_turno_bbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variação percentual entre o 1º dia dos meses de Janeiro a Setembro e o 2º turno (segunda-feira pós 2º turno)\n",
    "dict_meses_2_turno = {}\n",
    "\n",
    "for segundo_turno, ano in zip(lst_segunda_feira_pos_2_turno, anos_eleicoes):\n",
    "    pct_change_jan_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-01'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_feb_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-02'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_mar_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-03'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_apr_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-04'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_may_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-05'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jun_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-06'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_jul_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-07'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_aug_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-08'].iloc[0]) - 1) * 100, 2)\n",
    "    pct_change_sep_2_turno = round(((df_bbas.loc[segundo_turno] / df_bbas[f'{ano}-09'].iloc[0]) - 1) * 100, 2)\n",
    "    \n",
    "    # Armazena um novo dicionário com chaves para cada mês\n",
    "    dict_meses_2_turno[ano] = {\n",
    "        'Jan': pct_change_jan_2_turno,\n",
    "        'Feb': pct_change_feb_2_turno,\n",
    "        'Mar': pct_change_mar_2_turno,\n",
    "        'Apr': pct_change_apr_2_turno,\n",
    "        'May': pct_change_may_2_turno,\n",
    "        'Jun': pct_change_jun_2_turno,\n",
    "        'Jul': pct_change_jul_2_turno,\n",
    "        'Aug': pct_change_aug_2_turno,\n",
    "        'Sep': pct_change_sep_2_turno\n",
    "    }\n",
    "\n",
    "# Transformando o dicionário em um df\n",
    "df_pct_change_meses_2_turno_bbas = pd.DataFrame(dict_meses_2_turno).T\n",
    "df_pct_change_meses_2_turno_bbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno diário\n",
    "ret_diario_bbas = df_vale.pct_change()\n",
    "\n",
    "# Criando uma lista com os drawdowns de cada ano eleitoral\n",
    "lista_drawdowns_eleitorais_bbas = [f_br.drawdown(ret_diario_bbas.loc[f'{ano}']) for ano in anos_eleitorais]\n",
    "\n",
    "df_drawdowns_eleitorais_bbas = pd.DataFrame(lista_drawdowns_eleitorais_bbas, columns=['drawdown_ano_eleitoral'], index=anos_eleitorais)\n",
    "df_drawdowns_eleitorais_bbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno logarítmico\n",
    "ret_log_bbas = np.log(df_bbas / df_bbas.shift(1))\n",
    "\n",
    "# Calculando a volatilidade anualizada dos anos eleitorais\n",
    "lista_vol_anual_bbas = [(ret_log_bbas.loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_eleitorais]\n",
    "\n",
    "df_vol_anual_bbas = pd.DataFrame(lista_vol_anual_bbas, columns=['vol_anual'], index=anos_eleitorais)\n",
    "df_vol_anual_bbas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anos de Crises - BRASIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados do papel em específico\n",
    "ticker = '^BVSP'\n",
    "ativo = yf.download(ticker, start='1995-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "\n",
    "# Resetando o index do df\n",
    "ativo = ativo.reset_index()  \n",
    "\n",
    "# Renomeando as colunas para remover o MultiIndex\n",
    "ativo.columns = ['Date', 'Close']  \n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "ativo = ativo.set_index('Date')\n",
    "\n",
    "# Fazendo uma copia do df ativo\n",
    "df = ativo.copy()\n",
    "\n",
    "# Cria uma coluna para o ano de cada dia\n",
    "df['ano'] = df.index.year \n",
    "\n",
    "# Cria uma coluna para o nº inteiro de cada dia -> 1 = primeiro dia do ano ... 365 = último dia do ano\n",
    "df['dia_do_ano'] = df.index.dayofyear \n",
    "\n",
    "# Criando a tabela pivot\n",
    "tabela = df.pivot(index='dia_do_ano', columns='ano', values='Close')\n",
    "\n",
    "# Utilizo o método 'bfill' para completar os NaN\n",
    "tabela_final = tabela.bfill()\n",
    "\n",
    "# Tranformo a tabela dos preços de fechamento para a variação percentual do dia\n",
    "tabela_final = (tabela_final / tabela_final.iloc[0]) - 1\n",
    "\n",
    "# Plotando o gráfico de anos de crises\n",
    "anos_crises = [1998, 2000, 2008, 2014, 2020]\n",
    "\n",
    "fig = px.line(tabela_final[anos_crises], \n",
    "              height=600, \n",
    "              width=800, \n",
    "              template='plotly_dark',\n",
    "              title='Performance IBOVESPA em anos de crises',\n",
    "              labels={'value':'retorno'})\n",
    "\n",
    "# Mudando a espessura da linha do gráfico\n",
    "fig.update_traces(line=dict(width=1))\n",
    "\n",
    "# Formatando o eixo y do gráfico para aparecer em %\n",
    "fig.layout.yaxis.tickformat = '.0%'\n",
    "\n",
    "# Criando duas linhas verticais no início e fim de Outubro\n",
    "fig.add_hline(y=0)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno anual dos anos de crises\n",
    "lista_ret_ano = [round((((df.loc[f'{ano}-12', 'Close'].iloc[-1] / df.loc[f'{ano}-01', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_crises]\n",
    "\n",
    "df_ret_crise = pd.DataFrame(lista_ret_ano, \n",
    "                            columns=['retorno_anual_crise'], \n",
    "                            index=anos_crises\n",
    ")\n",
    "\n",
    "df_ret_crise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno diário\n",
    "ret_diario = df_ibov.pct_change()\n",
    "\n",
    "# Criando uma lista com os drawdowns de cada ano de crise\n",
    "lista_drawdowns_crises = [f_br.drawdown(ret_diario.loc[f'{ano}']) for ano in anos_crises]\n",
    "\n",
    "df_drawdowns_crises = pd.DataFrame(lista_drawdowns_crises, columns=['drawdown_anos_crises'], index=anos_crises)\n",
    "df_drawdowns_crises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno logarítmico\n",
    "ret_log = np.log(df_ibov / df_ibov.shift(1))\n",
    "\n",
    "# Calculando a volatilidade anualizada dos anos crises\n",
    "lista_vol_anual_crises = [(ret_log.loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_crises]\n",
    "\n",
    "df_vol_anual_crises = pd.DataFrame(lista_vol_anual_crises, columns=['vol_anual'], index=anos_crises)\n",
    "df_vol_anual_crises\n",
    "\n",
    "## Utilizando o retorno normal, a volatilidade anual fica parecida com a volatilidade anual do retorno logarítmico\n",
    "# lista_vol_anual_crises = [(df['ret_diario'].loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_crises]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimas (fundos) das crises\n",
    "minimas_crises = [ativo.loc[f'{ano}', 'Close'].min() for ano in anos_crises]\n",
    "\n",
    "# Indexes das minimas das crises\n",
    "idx_minimas = [ativo.loc[f'{ano}', 'Close'].idxmin() for ano in anos_crises]\n",
    "\n",
    "# Máximas (topos) prévias dos fundos das crises\n",
    "maximas_previas = [ativo.loc[:idx_minimas[i], 'Close'].max() for i in range(len(anos_crises))]\n",
    "\n",
    "# Criando dfs pós crise de cada ano p/ achar os indexes dos dias que o preço volta p/ o patamar das máximas anteriores as crises\n",
    "df_pos_crise = {i: ativo.loc[idx_minimas[i]:, 'Close'] for i in range(len(anos_crises))}\n",
    "# Lógica do dict comprehension\n",
    "# df = {}\n",
    "# for i in range(len(idx_minimas)):\n",
    "#   df[i] = ativo.loc[idx_minimas[i]:, 'Close']\n",
    "\n",
    "# Lista dos indexes dos dias que recupera o preço da máxima anterior da crise\n",
    "idx_rec = [df_pos_crise[i].loc[ativo.loc[idx_minimas[i]:, 'Close'] >= maximas_previas[i]].index[0] for i in range(len(anos_crises))]\n",
    "# Ficou confuso na list comprehension. A lógica dela é:\n",
    "# lista_idx_rec = []\n",
    "# for i in range(len(idx_minimas)):\n",
    "#   filt = ativo.loc[idx_minimas[i]:, 'Close'] >= maximas_previas[i]  # Filtro que seleciona os dias em que alcança o preço da máxima anterior da crise.\n",
    "#   idx_rec = df_pos_crise[i].loc[filt].index[0]                           # Seleciono o index do primeiro dia que se alcança o preço da máxima anterior da crise.\n",
    "#   lista_idx_rec.append(idx_rec)\n",
    "\n",
    "# Para eu saber a diferença entre as datas de minimas das crises e topos anteriores, eu vejo o tamanho do df a partir do slice idx_minimas[i]:idx_rec[i]\n",
    "# Eu não preciso usar o np.busday_count, pq eu estou utilizando os dados do yahoo finance que contém apenas os dias em que a bolsa opera\n",
    "lista_dias_rec = [len(ativo.loc[idx_minimas[i]:idx_rec[i], 'Close']) for i in range(len(anos_crises))]\n",
    "\n",
    "## Convertendo de timestamp p/ datetime. Para ficar apenas as datas no df (se fica em timestamp aparece as horas -> 1998-09-10 00:00:00-03:00)\n",
    "idx_rec2 = list(map(lambda x: x.date(), idx_rec))\n",
    "idx_minimas2 = list(map(lambda x: x.date(), idx_minimas))\n",
    "\n",
    "# Juntando todas as listas criadas em um df\n",
    "df_crise_br = pd.DataFrame(list(zip(idx_minimas2, minimas_crises, maximas_previas, idx_rec2, lista_dias_rec)),\n",
    "                        columns=['data_minimas','minimas_crises', 'maximas_previas', 'data_recuperacao', 'dias_recuperacao'], \n",
    "                        index=anos_crises)\n",
    "\n",
    "df_crise_br\n",
    "\n",
    "\n",
    "\n",
    "# Apenas p/ estudos, utilizando o np.busday_count (*** DÁ UM POUCO DE DIFERENÇA NOS DIAS DE RECUPERAÇÃO ***)\n",
    "\n",
    "## Convertendo de timestamp p/ datetime. Deste modo, posso usar o np.busday_count()\n",
    "# idx_rec2 = list(map(lambda x: x.date(), idx_rec))\n",
    "# idx_minimas2 = list(map(lambda x: x.date(), idx_minimas))\n",
    "\n",
    "## Lendo o arquivo da feriados_anbima.\n",
    "# holidays_br = pd.read_excel('/content/drive/MyDrive/Séries Históricas/ANBIMA/feriados_anbima.xlsx')\n",
    "# holidays_br['data'] = holidays_br.loc[:, 'data'].astype(str)\n",
    "# holidays_br = list(holidays_br['data'])\n",
    "\n",
    "## Quantos dias demorou p/ o mercado voltar ao topo prévio pós-crise, considerando apenas os dias úteis.\n",
    "# lista_dias_rec = [np.busday_count(idx_minimas2[i], idx_rec2[i], holidays=holidays_br) for i in range(len(idx_minimas))]\n",
    "\n",
    "## Criando o df das crises dos EUA.\n",
    "# df_crise_br = pd.DataFrame(list(zip(minimas_crises, maximas_previas, lista_dias_rec)),\n",
    "#                         columns=['minimas_crises', 'maximas_previas', 'dias_recuperacao'], \n",
    "#                         index=anos_crises)\n",
    "\n",
    "# df_crise_br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anos Eleitorais - EUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados do papel em específico\n",
    "ticker = '^GSPC' # Os dados do S&P500 começam no ano de 1950\n",
    "ativo_eua = yf.download(ticker, start='1995-01-01', auto_adjust=True, multi_level_index=False)\n",
    "\n",
    "# Resetando o index do df\n",
    "ativo_eua = ativo_eua.reset_index()  \n",
    "\n",
    "# Renomeando as colunas para remover o MultiIndex\n",
    "ativo_eua.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']  \n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "ativo_eua = ativo_eua.set_index('Date')\n",
    "\n",
    "# Fazendo uma copia do df ativo\n",
    "df_eua = ativo_eua.copy()\n",
    "\n",
    "# Cria uma coluna para o ano de cada dia\n",
    "df_eua['ano'] = df_eua.index.year \n",
    "\n",
    "# Cria uma coluna para o nº inteiro de cada dia -> 1 = primeiro dia do ano ... 365 = último dia do ano\n",
    "df_eua['dia_do_ano'] = df_eua.index.dayofyear \n",
    "\n",
    "# Criando a tabela pivot\n",
    "tabela_eua = df_eua.pivot(index='dia_do_ano', columns='ano', values='Close')\n",
    "\n",
    "# Utilizo o método 'bfill' para completar os NaN\n",
    "tabela_eua_final = tabela_eua.bfill()\n",
    "\n",
    "# Tranformo a tabela dos preços de fechamento para a variação percentual do dia\n",
    "tabela_eua_final = (tabela_eua_final / tabela_eua_final.iloc[0]) - 1\n",
    "\n",
    "tabela_eua_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o gráfico dos anos eleitorais\n",
    "anos_eleitorais = [\n",
    "    1996, 2000, 2004, 2008, \n",
    "    2012, 2016, 2020, 2024\n",
    "]\n",
    "\n",
    "fig = px.line(tabela_eua_final[anos_eleitorais], \n",
    "              height=600, \n",
    "              width=800, \n",
    "              template='plotly_dark',\n",
    "              title='Performance S&P500 em anos eleitorais',\n",
    "              labels={'value':'retorno'})\n",
    "\n",
    "# Mudando a espessura da linha do gráfico\n",
    "fig.update_traces(line=dict(width=1))\n",
    "\n",
    "# Criando duas linhas verticais no início de Novembro\n",
    "fig.add_vline(x=pd.to_datetime('2022-11-01').dayofyear)\n",
    "\n",
    "# Formatando o eixo y do gráfico para aparecer em %\n",
    "fig.layout.yaxis.tickformat = '.0%'\n",
    "\n",
    "# Criando duas linhas verticais no início e fim de Outubro\n",
    "fig.add_hline(y=0)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anos de Crises - EUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados do papel em específico\n",
    "ticker = '^GSPC' # Os dados do S&P500 começam no ano de 1950\n",
    "ativo_eua = yf.download(ticker, start='1987-01-01', auto_adjust=True, multi_level_index=False)\n",
    "\n",
    "# Resetando o index do df\n",
    "ativo_eua = ativo_eua.reset_index()  \n",
    "\n",
    "# Renomeando as colunas para remover o MultiIndex\n",
    "ativo_eua.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']  \n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "ativo_eua = ativo_eua.set_index('Date')\n",
    "\n",
    "# Fazendo uma copia do df ativo\n",
    "df_eua = ativo_eua.copy()\n",
    "\n",
    "# Cria uma coluna para o ano de cada dia\n",
    "df_eua['ano'] = df_eua.index.year \n",
    "\n",
    "# Cria uma coluna para o nº inteiro de cada dia -> 1 = primeiro dia do ano ... 365 = último dia do ano\n",
    "df_eua['dia_do_ano'] = df_eua.index.dayofyear \n",
    "\n",
    "# Criando a tabela pivot\n",
    "tabela_eua = df_eua.pivot(index='dia_do_ano', columns='ano', values='Close')\n",
    "\n",
    "# Utilizo o método 'bfill' para completar os NaN\n",
    "tabela_eua_final = tabela_eua.bfill()\n",
    "\n",
    "# Tranformo a tabela dos preços de fechamento para a variação percentual do dia\n",
    "tabela_eua_final = (tabela_eua_final / tabela_eua_final.iloc[0]) - 1\n",
    "\n",
    "# Plotando o gráfico dos anos de crises\n",
    "# https://www.investopedia.com/timeline-of-stock-market-crashes-5217820\n",
    "anos_crises = [\n",
    "    1987, # Black Monday\n",
    "    2000, # Dot-com bubble\n",
    "    2008, # Sub-prime bubble\n",
    "    2010, # Flash crash\n",
    "    2015, # Stock market selloff\n",
    "    2020  # Covid crash\n",
    "]\n",
    "\n",
    "fig = px.line(tabela_eua_final[anos_crises], \n",
    "              height=600, \n",
    "              width=800, \n",
    "              template='plotly_dark',\n",
    "              title='Performance S&P500 em anos de crises',\n",
    "              labels={'value':'retorno'})\n",
    "\n",
    "# Mudando a espessura da linha do gráfico\n",
    "fig.update_traces(line=dict(width=1))\n",
    "\n",
    "# Formatando o eixo y do gráfico para aparecer em %\n",
    "fig.layout.yaxis.tickformat = '.0%'\n",
    "\n",
    "# Criando duas linhas verticais no início e fim de Outubro\n",
    "fig.add_hline(y=0)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno anual dos anos de crises\n",
    "lista_ret_ano_eua = [round((((df_eua.loc[f'{ano}-12', 'Close'].iloc[-1] / df_eua.loc[f'{ano}-01', 'Close'].iloc[0]))-1)*100, 2) for ano in anos_crises]\n",
    "\n",
    "df_ret_crise_eua = pd.DataFrame(lista_ret_ano_eua, \n",
    "                            columns=['retorno_anual_crise'], \n",
    "                            index=anos_crises\n",
    ")\n",
    "\n",
    "df_ret_crise_eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno diário\n",
    "ret_diario_eua = df_eua['Close'].pct_change()\n",
    "\n",
    "# Criando uma lista com os drawdowns de cada ano de crise\n",
    "lista_drawdowns_crises_eua = [f_br.drawdown(ret_diario_eua.loc[f'{ano}']) for ano in anos_crises]\n",
    "\n",
    "df_drawdowns_crises_eua = pd.DataFrame(lista_drawdowns_crises_eua, columns=['drawdown_anos_crises'], index=anos_crises)\n",
    "df_drawdowns_crises_eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a volatilidade anualizada dos anos crises\n",
    "lista_vol_anual_crises_eua = [(ret_diario_eua.loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_crises]\n",
    "\n",
    "df_vol_anual_crises_eua = pd.DataFrame(lista_vol_anual_crises_eua, columns=['vol_anual'], index=anos_crises)\n",
    "df_vol_anual_crises_eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno logarítmico\n",
    "ret_log_eua = np.log(df_eua['Close'] / df_eua['Close'].shift(1))\n",
    "\n",
    "# Calculando a volatilidade anualizada dos anos eleitorais\n",
    "lista_vol_anual_eua = [(ret_log_eua.loc[f'{anos}'].std() * np.sqrt(252) * 100) for anos in anos_eleitorais]\n",
    "\n",
    "df_vol_anual_eua = pd.DataFrame(lista_vol_anual_eua, columns=['vol_anual'], index=anos_eleitorais)\n",
    "df_vol_anual_eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimas (fundos) das crises\n",
    "minimas_crises = [ativo_eua.loc[f'{ano}', 'Close'].min() for ano in anos_crises]\n",
    "\n",
    "# Indexes das minimas das crises\n",
    "idx_minimas = [ativo_eua.loc[f'{ano}', 'Close'].idxmin() for ano in anos_crises]\n",
    "\n",
    "# Máximas (topos) prévias dos fundos das crises\n",
    "maximas_previas = [ativo_eua.loc[:idx_minimas[i], 'Close'].max() for i in range(len(idx_minimas))]\n",
    "\n",
    "# Criando dfs pós crise de cada ano p/ achar os indexes dos dias que o preço volta p/ o patamar das máximas anteriores as crises\n",
    "df_pos_crise = {i: ativo_eua.loc[idx_minimas[i]:, 'Close'] for i in range(len(idx_minimas))}\n",
    "# Lógica do dict comprehension\n",
    "# df = {}\n",
    "# for i in range(len(idx_minimas)):\n",
    "#   df[i] = ativo2.loc[idx_minimas[i]:, 'Close']\n",
    "\n",
    "# Lista dos indexes dos dias que recupera o preço da máxima anterior da crise\n",
    "idx_rec = [df_pos_crise[i].loc[ativo_eua.loc[idx_minimas[i]:, 'Close'] >= maximas_previas[i]].index[0] for i in range(len(idx_minimas))]\n",
    "# Ficou confuso na list comprehension. A lógica dela é:\n",
    "# lista_idx_rec = []\n",
    "# for i in range(len(idx_minimas)):\n",
    "#   filt = ativo2.loc[idx_minimas[i]:, 'Close'] >= maximas_previas[i]  # Filtro que seleciona os dias em que alcança o preço da máxima anterior da crise.\n",
    "#   idx_rec = df_pos_crise[i].loc[filt].index[0]                           # Seleciono o index do primeiro dia que se alcança o preço da máxima anterior da crise.\n",
    "#   lista_idx_rec.append(idx_rec)\n",
    "\n",
    "# Para eu saber a diferença entre as datas de minimas das crises e topos anteriores, eu vejo o tamanho do df a partir do slice idx_minimas[i]:idx_rec[i]\n",
    "# Eu não preciso usar o np.busday_count, pq eu estou utilizando os dados do yahoo finance que contém apenas os dias em que a bolsa opera\n",
    "lista_dias_rec = [len(ativo_eua.loc[idx_minimas[i]:idx_rec[i], 'Close']) for i in range(len(anos_crises))]\n",
    "\n",
    "## Convertendo de timestamp p/ datetime. Para ficar apenas as datas no df (se fica em timestamp aparece as horas -> 1998-09-10 00:00:00-03:00)\n",
    "idx_rec2 = list(map(lambda x: x.date(), idx_rec))\n",
    "idx_minimas2 = list(map(lambda x: x.date(), idx_minimas))\n",
    "\n",
    "# Juntando todas as listas criadas em um df\n",
    "df_crise_eua = pd.DataFrame(list(zip(idx_minimas2, minimas_crises, maximas_previas, idx_rec2, lista_dias_rec)),\n",
    "                        columns=['data_minimas','minimas_crises', 'maximas_previas','data_recuperacao', 'dias_recuperacao'], \n",
    "                        index=anos_crises)\n",
    "\n",
    "df_crise_eua\n",
    "\n",
    "\n",
    "\n",
    "## Convertendo de timestamp p/ datetime. Deste modo, posso usar o np.busday_count()\n",
    "# idx_rec2 = list(map(lambda x: x.date(), idx_rec))\n",
    "# idx_minimas2 = list(map(lambda x: x.date(), idx_minimas))\n",
    "\n",
    "## Quantos dias demorou p/ o mercado voltar ao topo prévio pós-crise, considerando apenas os dias úteis.\n",
    "# lista_dias_rec = [np.busday_count(idx_minimas2[i], idx_rec2[i]) for i in range(len(idx_minimas))]\n",
    "\n",
    "## Criando o df das crises dos EUA.\n",
    "# df_crise_eua = pd.DataFrame(list(zip(minimas_crises, maximas_previas, lista_dias_rec)),\n",
    "#                         columns=['minimas_crises', 'maximas_previas', 'dias_recuperacao'], \n",
    "#                         index=anos_crises)\n",
    "\n",
    "# df_crise_eua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bolha Dotcom vs AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estudo comparativo do retorno acumulado do NASDAQ pós Netscape e pós ChatGPT (https://www.bespokepremium.com/interactive/posts/think-big-blog/ai-vs-the-web)\n",
    "# Vídeo que mostra o estudo: https://www.youtube.com/watch?v=4a-TzdF8IMk\n",
    "\n",
    "# Download dos dados da Nasdaq\n",
    "ticker = '^IXIC' \n",
    "\n",
    "# Data pós Netscape de 01/12/1994 até 24/03/2000 (pico da bolha dot com)\n",
    "nasdaq_post_netscape = yf.download(ticker, start='1994-12-01', end='2000-03-24', auto_adjust=True, multi_level_index=False)\n",
    "nasdaq_post_netscape['pct_change'] = nasdaq_post_netscape['Close'].pct_change().dropna()\n",
    "\n",
    "# Data pós Chatgpt de 30/11/2022 até o presente\n",
    "nasdaq_post_chatgpt = yf.download(ticker, start='2022-11-30', auto_adjust=True, multi_level_index=False)\n",
    "nasdaq_post_chatgpt['pct_change'] = nasdaq_post_chatgpt['Close'].pct_change().dropna()\n",
    "\n",
    "# Calculando o retorno acumulado\n",
    "ret_accum_nasdaq_post_netscape = (1 + nasdaq_post_netscape['pct_change']).cumprod()\n",
    "ret_accum_nasdaq_post_chatgpt = (1 + nasdaq_post_chatgpt['pct_change']).cumprod()\n",
    "\n",
    "# Normalizando o eixo x para a quantidade de dias desde o início de cada período\n",
    "ret_accum_nasdaq_post_netscape_days = (ret_accum_nasdaq_post_netscape.index - ret_accum_nasdaq_post_netscape.index[0]).days\n",
    "ret_accum_nasdaq_post_chatgpt_days = (ret_accum_nasdaq_post_chatgpt.index - ret_accum_nasdaq_post_chatgpt.index[0]).days\n",
    "\n",
    "# Plot do retorno acumulado\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter( \n",
    "    x=ret_accum_nasdaq_post_netscape_days, # Usar os dias como eixo x\n",
    "    y=ret_accum_nasdaq_post_netscape,\n",
    "    mode='lines',\n",
    "    name='Pós Netscape',\n",
    "    line=dict(color='blue', width=2)\n",
    ")) \n",
    "\n",
    "fig.add_trace(go.Scatter( \n",
    "    x=ret_accum_nasdaq_post_chatgpt_days, # Usar os dias como eixo x\n",
    "    y=ret_accum_nasdaq_post_chatgpt,\n",
    "    mode='lines',\n",
    "    name='Pós ChatGPT',\n",
    "    line=dict(color='red', width=2) \n",
    ")) \n",
    "\n",
    "fig.update_layout(\n",
    "    title='Retorno Acumulado do NASDAQ pós Netscape e ChatGPT (Comparação de Dias)',\n",
    "    xaxis_title='Dias desde o Início do Período', \n",
    "    yaxis_title='Retorno Acumulado', \n",
    "    template='plotly_white',\n",
    "    hovermode=\"x unified\" # Adicionado para melhor visualização ao passar o mouse\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Maiores Sequências Alta/Baixa de um Ativo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_streak = f_br.maior_streak(ticker='BOVA11.SA', start='2012-01-01')\n",
    "\n",
    "# Df com a sequência de altas\n",
    "print(df_streak[0])\n",
    "print('-'*50)\n",
    "\n",
    "# Df com a sequência de baixas\n",
    "print(df_streak[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecionar uma determinada sequência específica tanto de alta/baixa de um ativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tutorial: https://blog.devgenius.io/streaks-in-pandas-time-series-c63fe62aa771\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados\n",
    "ticker = 'ABEV3.SA'\n",
    "start = '2012-01-01'\n",
    "\n",
    "# Fazendo o dowload do ativo\n",
    "df = yf.download(ticker, start, auto_adjust=True)['Close']\n",
    "\n",
    "# Resetando o index do df\n",
    "df = df.reset_index()\n",
    "\n",
    "# Renomeando as colunas\n",
    "df.columns = ['Date', 'Close']\n",
    "\n",
    "# Transformando a coluna 'Date' no index do df\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Calculando as sequências de alta/baixa do ativo\n",
    "df['returns'] = df['Close'].pct_change()\n",
    "df['growing'] = df['Close'].gt(df['Close'].shift())\n",
    "df['streak_start'] = (df['growing'].ne(df['growing'].shift()))\n",
    "df['streak_no'] = df['streak_start'].cumsum()\n",
    "df['streak_count'] = df.groupby('streak_no').cumcount().add(1)\n",
    "\n",
    "# Mostrando a maior sequência do ativo\n",
    "idx_max = df['streak_count'].idxmax()\n",
    "max_streak_length = df.loc[idx_max, 'streak_count']\n",
    "df_max_streak = df.loc[:idx_max, ['Close', 'streak_count']].tail(max_streak_length)\n",
    "\n",
    "df_max_streak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando o 'streak_count' para encontrar quais os outros dias de grandes sequências\n",
    "filt_maiores_streaks = df['streak_count'] == 9\n",
    "df.loc[filt_maiores_streaks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para mostrar a sequência específica, basta colocar o index do dia da sequência\n",
    "idx = '2024-05-29'\n",
    "streak_length = df.loc[idx, 'streak_count']\n",
    "df.loc[:idx, ['Close', 'streak_count']].tail(streak_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Monte Carlo Simulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation of a Stock Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Video da aula: https://www.youtube.com/watch?v=6-dhdMDiYWQ&list=PLqpCwow11-OqqfELduCMcRI6wcnoM3GAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockList = ['PETR4.SA', 'VALE3.SA', 'TAEE11.SA', 'ITUB4.SA']\n",
    "endDate = datetime.now()\n",
    "startDate = endDate - timedelta(days=300)\n",
    "\n",
    "meanReturns, covMatrix = f_br.get_data(stocks=stockList, start=startDate, end=endDate)\n",
    "\n",
    "weights = np.random.random(len(meanReturns))\n",
    "weights /= np.sum(weights)\n",
    "\n",
    "# Monte Carlo Simulation\n",
    "n_sims = 100 # número de simulações\n",
    "t = 100 # timeframe in days\n",
    "\n",
    "meanM = np.full(shape=(t, len(weights)), fill_value=meanReturns)  # Matriz com os retornos\n",
    "meanM = meanM .T # Matriz transposta\n",
    "\n",
    "portfolio_sims = np.full(shape=(t, n_sims), fill_value=0.0)  # Matriz de zeros \n",
    "\n",
    "initialPortfolio = 10_000 # quanto dinheiro começou com o portfolio\n",
    "\n",
    "for m in range(0, n_sims):\n",
    "    Z = np.random.normal(size=(t, len(weights)))\n",
    "    L = np.linalg.cholesky(covMatrix)\n",
    "    dailyReturns = meanM + np.inner(L, Z)\n",
    "    portfolio_sims[:, m] = np.cumprod(np.inner(weights, dailyReturns.T) + 1) * initialPortfolio\n",
    "\n",
    "\n",
    "# Plotando o gráfico\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(portfolio_sims)\n",
    "plt.ylabel('Portfolio Value (R$)')\n",
    "plt.xlabel('Days')\n",
    "plt.title('Monte Carlo Simulation of a Stock Portfolio');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Video da aula: https://www.youtube.com/watch?v=f9MAFvP5-pA&list=PLqpCwow11-OqqfELduCMcRI6wcnoM3GAZ&index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolioResults = pd.Series(portfolio_sims[-1, :])\n",
    "\n",
    "VaR = initialPortfolio - f_br.mcVaR(portfolioResults, alpha=5)\n",
    "CVaR = initialPortfolio - f_br.mcCVaR(portfolioResults, alpha=5)\n",
    "\n",
    "print(f'VaR R${round(VaR, 2)}')\n",
    "print(f'CVaR R${round(CVaR, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation of Drawdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vídeo da aula: https://www.youtube.com/watch?v=jJ6mZuI28kQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = '^BVSP'\n",
    "start = '2010-01-01'\n",
    "end = datetime.today().strftime('%Y-%m-%d')\n",
    "df = yf.download(tickers=ticker, start=start, end=end, auto_adjust=True, multi_level_index=False)\n",
    "\n",
    "# Calculando o retorno diário\n",
    "df['returns'] = df['Close'].pct_change()\n",
    "returns = df['Close'].pct_change().dropna().to_numpy().flatten()\n",
    "\n",
    "# Vamos considerar 3 anos para frente e que 1 ano tenha 252 dias úteis\n",
    "years = 3\n",
    "num_days = years * 252\n",
    "last_price = float(df['Close'].iloc[-1])\n",
    "\n",
    "# Simulação de Monte Carlo do drawdown\n",
    "num_sim = 100000 # nº de simulações\n",
    "\n",
    "dd = np.array([]) # matriz vazia que vai guardar os drawdowns\n",
    "\n",
    "for n in range(num_sim):\n",
    "    # Etapas do cálculo do drawdown\n",
    "    # Simula os retornos diários dos próximos 3 anos\n",
    "    sim_ret = np.random.choice(returns, size=num_days, replace=True)\n",
    "\n",
    "    # Calculando o valor da carteira com retornos compostos\n",
    "    sim_val = last_price*(1+sim_ret).cumprod()\n",
    "\n",
    "    # Calculando o valor máximo da carteira simulada\n",
    "    max_val = np.maximum.accumulate(sim_val)\n",
    "\n",
    "    # Encontrando o drawdown máximo\n",
    "    max_dd = np.max((max_val - sim_val) / max_val)\n",
    "\n",
    "    # Acrescentando os dd na metriz vazia\n",
    "    dd = np.append(dd, max_dd)\n",
    "\n",
    "# Plotando a distribuição dos drawdowns com MC\n",
    "config = dict(histtype='stepfilled', alpha=0.7, density=False, bins=100)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(dd, **config, label='Drawdown')\n",
    "plt.xlabel('Retorno do drawdown')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend(loc='upper right',\n",
    "           frameon=True,\n",
    "           ncol=2,\n",
    "           fancybox=True,\n",
    "           framealpha=0.95,\n",
    "           shadow=True,\n",
    "           borderpad=1\n",
    ")\n",
    "plt.title(f'Distribuição dos drawdowns {ticker} com a simulação de MC')\n",
    "\n",
    "# Estatísticas\n",
    "print(f'Para o ativo {ticker}, segundo uma simulação de MC com {num_sim} simulações em {years} anos, podemos esperar:')\n",
    "print('-'*70)\n",
    "print(f'Drawdown médio de {round(np.mean(dd*100), 2)}%')\n",
    "print()\n",
    "print('Com: ')\n",
    "print(f' 50% de probabilidade, o DD será maior do que {round(np.median(dd*100), 2)}%')\n",
    "print(f' 25% de probabilidade, o DD será maior do que {round(np.percentile(dd*100, 75), 2)}%')\n",
    "print(f' 5% de probabilidade, o DD será maior do que {round(np.percentile(dd*100, 95), 2)}%')\n",
    "print('-'*70)\n",
    "print(f'Período dos parâmetros para a simulação {start} a {end}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas-montecarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://pypi.org/project/pandas-montecarlo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_montecarlo # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados do ativo\n",
    "ticker = 'BOVA11.SA'\n",
    "df = yf.download(ticker, start='2009-01-01', auto_adjust=True, multi_level_index=False)\n",
    "df['return'] = df['Close'].pct_change().fillna(0)\n",
    "\n",
    "# Simulação de Monte Carlo\n",
    "mc = df['return'].montecarlo(sims=1000, bust=-1, goal=0)\n",
    "\n",
    "# Plotando a simulação de Monte Carlos\n",
    "mc.plot(title=f'{ticker} - Simulação de Monte Carlos', figsize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando os testes estatísticos\n",
    "# 'maxdd': max drawdown\n",
    "# 'bust': probability of going bust\n",
    "# 'goal': probability of reaching 100% goal\n",
    "mc.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Mostra as estatíticas do max drawdown \n",
    "mc.maxdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostras o raw df das simulações \n",
    "mc.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entropia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropia Estrutural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://towardsdatascience.com/entropy-application-in-the-stock-market-b211914ed1f3\n",
    "\n",
    "* https://github.com/cerlymarco/MEDIUM_NoteBook/blob/master/Structural_Entropy/Structural_Entropy.ipynb\n",
    "\n",
    "* Eu fiz o download do paper \"Structural Entropy Monitoring Correlation-Based Networks Over Time With Application to Financial Markets\" que explica o conceito;\n",
    "* Apliquei o código para os ativos brasileiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando os dados das ações brasileiras\n",
    "lista_acoes = [\n",
    "    'PETR4.SA', \n",
    "    'PRIO3.SA',\n",
    "    'VALE3.SA', \n",
    "    'ITUB4.SA', \n",
    "    'BBDC3.SA',\n",
    "    'BBAS3.SA', \n",
    "    'MGLU3.SA',\n",
    "    'WEGE3.SA', \n",
    "    'EGIE3.SA', \n",
    "    'TAEE11.SA', \n",
    "    'ISAE4.SA',\n",
    "    'CPLE3.SA', \n",
    "    'RANI3.SA', \n",
    "    'SUZB3.SA', \n",
    "    'ABEV3.SA', \n",
    "]\n",
    "\n",
    "# Selecionando o 'Close'\n",
    "df_carteira = yf.download(lista_acoes, start='2017-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "df_carteira = df_carteira.loc[~df_carteira.isna().any(axis=1)].copy()\n",
    "print(df_carteira.shape)\n",
    "df_carteira.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o retorno logaritmo\n",
    "carteira_logret = (df_carteira .pct_change()).apply(np.log1p)\n",
    "print(carteira_logret.shape)\n",
    "carteira_logret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando a correlação e a distribuição dos retornos logaritmos\n",
    "plt.figure(figsize=(18,7))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(carteira_logret.corr())\n",
    "plt.title('logret correlation')\n",
    "\n",
    "plt.subplot(122)\n",
    "carteira_logret.plot.hist(\n",
    "    bins=100, \n",
    "    legend=False, \n",
    "    ax=plt.gca(), \n",
    "    title='logret distributions'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o média e o desvio-padrão deslizantes do retorno logaritmo\n",
    "sequence_length = 200\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "carteira_logret.rolling(sequence_length).mean().plot(\n",
    "    legend=False, \n",
    "    color='blue', \n",
    "    alpha=0.3, \n",
    "    ax=plt.gca(), \n",
    "    title='logret sliding mean'\n",
    ")\n",
    "\n",
    "carteira_logret.rolling(sequence_length).mean().median(axis=1).plot(\n",
    "    color='red', \n",
    "    linewidth=3, \n",
    "    ax=plt.gca()\n",
    ")\n",
    "\n",
    "plt.subplot(122)\n",
    "carteira_logret.rolling(sequence_length).std().plot(\n",
    "    legend=False, \n",
    "    color='blue', \n",
    "    alpha=0.3, \n",
    "    ax=plt.gca(), \n",
    "    title='logret sliding std'\n",
    ")\n",
    "\n",
    "carteira_logret.rolling(sequence_length).std().median(axis=1).plot(\n",
    "    color='red', \n",
    "    linewidth=3, \n",
    "    ax=plt.gca()\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a entropia estrutural para a carteira_logret\n",
    "sequence_length_carteira = 200\n",
    "structural_entropy_05 = f_br.structural_entropy(carteira_logret, sequence_length_carteira, 0.5)\n",
    "structural_entropy_06 = f_br.structural_entropy(carteira_logret, sequence_length_carteira, 0.6)\n",
    "structural_entropy_07 = f_br.structural_entropy(carteira_logret, sequence_length_carteira, 0.7)\n",
    "structural_entropy_08 = f_br.structural_entropy(carteira_logret, sequence_length_carteira, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando a entropia estrutural\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=structural_entropy_05.index, \n",
    "    y=structural_entropy_05['structural_entropy'], \n",
    "    name='Structural Entropy - 0.5'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=structural_entropy_06.index, \n",
    "    y=structural_entropy_06['structural_entropy'], \n",
    "    name='Structural Entropy - 0.6'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=structural_entropy_07.index, \n",
    "    y=structural_entropy_07['structural_entropy'], \n",
    "    name='Structural Entropy - 0.7'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=structural_entropy_08.index, \n",
    "    y=structural_entropy_08['structural_entropy'], \n",
    "    name='Structural Entropy - 0.8'\n",
    "))\n",
    "\n",
    "fig.update_layout(title='Structural Entropy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_entropy = structural_entropy_06.copy()\n",
    "\n",
    "# Dia com a maior entropia estrutural\n",
    "idx_max = reference_entropy['structural_entropy'].idxmax()\n",
    "max_structural = reference_entropy['structural_entropy'].max()\n",
    "print(f'O dia que teve a maior entropia estrutural foi de {max_structural:.4f} em {idx_max.date()}.')\n",
    "\n",
    "# Dia com a menor entropia estrutural\n",
    "idx_min = reference_entropy['structural_entropy'].idxmin()\n",
    "min_structural = reference_entropy['structural_entropy'].min()\n",
    "print(f'O dia que teve a menor entropia estrutural foi de {min_structural:.4f} em {idx_min.date()}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a volatilidade\n",
    "std_rolling = carteira_logret.rolling(sequence_length_carteira).std().median(axis=1) * 100  # Multipliquei por 100 para que o plot ficasse na mesma escala\n",
    "\n",
    "# Plotando a comparação entre a entropia estrutural e a volatilidade\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=reference_entropy.index, \n",
    "    y=reference_entropy['structural_entropy'], \n",
    "    name='Structural Entropy'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=std_rolling.index, \n",
    "    y=std_rolling.values, \n",
    "    name='Volatility'\n",
    "))\n",
    "\n",
    "fig.update_layout(title='Structural Entropy vs Volatility')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Relação Sinal-Ruído (SNR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vídeo da aula: https://www.youtube.com/watch?v=uo5Bq_SFvgs\n",
    "\n",
    "---\n",
    "\n",
    "* A relação sinal-ruído (SNR) é uma métrica que compara o nível do sinal desejado ao nível do ruído no sinal;\n",
    "* A SNR é geralmente expressa em decibéis (dB);\n",
    "* Um SNR alto indica que o nível do sinal é significamente maior que o nível do ruído.\n",
    "\n",
    "---\n",
    "\n",
    "* No plot da função \"plot_snr_vs_returns\", espera-se que:\n",
    " * Quanto maior for o desvio-padrão (maior ruído - \"noise\"), menor será o valor do SNR;\n",
    " * Quanto menor for o desvio-padrão (menor ruído - \"noise\"), maior será o valor do SNR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{SNR} = 10\\log_{10} \\left(\\frac{\\text{Psignal}}{\\text{Pnoise}}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados \n",
    "ticker = 'BOVA11.SA'\n",
    "df = yf.download(tickers=ticker, start='2018-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "df = df.reset_index()\n",
    "df.columns = ['Date', 'Close']\n",
    "df = df.set_index('Date')\n",
    "df['Returns'] = df['Close'].pct_change()\n",
    "df['STD'] = df['Returns'].rolling(20).std()\n",
    "# Selecionando o sinal (usaremos os preços de fechamento ajustados)\n",
    "signal = df['Close'].values\n",
    "dates = df.index\n",
    "\n",
    "# Calculando o rolling SNR com uma janela de 20 dias\n",
    "window = 20\n",
    "snr_values = f_br.rolling_snr(signal=signal, window=window)\n",
    "\n",
    "# Adicionando os valores do SNR no df\n",
    "df['SNR'] = snr_values\n",
    "\n",
    "# Plotando o rolling SNR e o STD\n",
    "f_br.plot_snr_adj_close(\n",
    "    ticker=ticker, \n",
    "    dates=dates, \n",
    "    close=df['Close'], \n",
    "    snr_values=df['SNR'],\n",
    "    window=window\n",
    ")\n",
    "\n",
    "# Plotando o scatter plot entre SNR e STD\n",
    "f_br.plot_snr_vs_returns(\n",
    "    snr_values=df['SNR'],\n",
    "    returns=df['STD']\n",
    ")\n",
    "\n",
    "# Sinais de trading com SNR\n",
    "df_trading = f_br.create_trading_signals(df=df, window=window)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.05, \n",
    "    subplot_titles=('Close', 'SNR')\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_trading.index,\n",
    "    y=df_trading['Close'],\n",
    "    mode='lines',\n",
    "    name='Close',\n",
    "    line=dict(color='blue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_trading.index,\n",
    "    y=df_trading['SNR'],\n",
    "    mode='lines',\n",
    "    name='SNR',\n",
    "    line=dict(color='red')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Adicionando os sinais de compra e venda no gráfico de preço\n",
    "buy_signals = df[df['Signal'] == 1]\n",
    "sell_signals = df[df['Signal'] == -1]\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=buy_signals.index,\n",
    "    y=buy_signals['Close'],\n",
    "    mode='markers',\n",
    "    name='Buy Signal',\n",
    "    marker=dict(color='green', size=10, symbol='triangle-up')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sell_signals.index,\n",
    "    y=sell_signals['Close'],\n",
    "    mode='markers',\n",
    "    name='Sell Signal',\n",
    "    marker=dict(color='red', size=10, symbol='triangle-down')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=ticker + ' - Close e SNR com Sinais de Trading',\n",
    "    height=1500,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Data', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Close', row=1, col=1)\n",
    "fig.update_yaxes(title_text='SNR (dB)', row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados \n",
    "ticker = 'QQQ'\n",
    "df = yf.download(tickers=ticker, start='2018-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "df = df.reset_index()\n",
    "df.columns = ['Date', 'Close']\n",
    "df = df.set_index('Date')\n",
    "df['Returns'] = df['Close'].pct_change()\n",
    "df['STD'] = df['Returns'].rolling(20).std()\n",
    "# Selecionando o sinal (usaremos os preços de fechamento ajustados)\n",
    "signal = df['Close'].values\n",
    "dates = df.index\n",
    "\n",
    "# Calculando o rolling SNR com uma janela de 20 dias\n",
    "window = 20\n",
    "snr_values = f_br.rolling_snr(signal=signal, window=window)\n",
    "\n",
    "# Adicionando os valores do SNR no df\n",
    "df['SNR'] = snr_values\n",
    "\n",
    "# Plotando o rolling SNR e o STD\n",
    "f_br.plot_snr_adj_close(\n",
    "    ticker=ticker, \n",
    "    dates=dates, \n",
    "    close=df['Close'], \n",
    "    snr_values=df['SNR'],\n",
    "    window=window\n",
    ")\n",
    "\n",
    "# Plotando o scatter plot entre SNR e STD\n",
    "f_br.plot_snr_vs_returns(\n",
    "    snr_values=df['SNR'],\n",
    "    returns=df['STD']\n",
    ")\n",
    "\n",
    "# Sinais de trading com SNR\n",
    "df_trading = f_br.create_trading_signals(df=df, window=window)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.05, \n",
    "    subplot_titles=('Close', 'SNR')\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_trading.index,\n",
    "    y=df_trading['Close'],\n",
    "    mode='lines',\n",
    "    name='Close',\n",
    "    line=dict(color='blue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_trading.index,\n",
    "    y=df_trading['SNR'],\n",
    "    mode='lines',\n",
    "    name='SNR',\n",
    "    line=dict(color='red')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Adicionando os sinais de compra e venda no gráfico de preço\n",
    "buy_signals = df[df['Signal'] == 1]\n",
    "sell_signals = df[df['Signal'] == -1]\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=buy_signals.index,\n",
    "    y=buy_signals['Close'],\n",
    "    mode='markers',\n",
    "    name='Buy Signal',\n",
    "    marker=dict(color='green', size=10, symbol='triangle-up')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sell_signals.index,\n",
    "    y=sell_signals['Close'],\n",
    "    mode='markers',\n",
    "    name='Sell Signal',\n",
    "    marker=dict(color='red', size=10, symbol='triangle-down')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=ticker + ' - Close e SNR com Sinais de Trading',\n",
    "    height=1500,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Data', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Close', row=1, col=1)\n",
    "fig.update_yaxes(title_text='SNR (dB)', row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados \n",
    "ticker = 'NVDA'\n",
    "df = yf.download(tickers=ticker, start='2018-01-01', auto_adjust=True, multi_level_index=False)['Close']\n",
    "df = df.reset_index()\n",
    "df.columns = ['Date', 'Close']\n",
    "df = df.set_index('Date')\n",
    "df['Returns'] = df['Close'].pct_change()\n",
    "df['STD'] = df['Returns'].rolling(20).std()\n",
    "# Selecionando o sinal (usaremos os preços de fechamento ajustados)\n",
    "signal = df['Close'].values\n",
    "dates = df.index\n",
    "\n",
    "# Calculando o rolling SNR com uma janela de 20 dias\n",
    "window = 20\n",
    "snr_values = f_br.rolling_snr(signal=signal, window=window)\n",
    "\n",
    "# Adicionando os valores do SNR no df\n",
    "df['SNR'] = snr_values\n",
    "\n",
    "# Plotando o rolling SNR e o STD\n",
    "f_br.plot_snr_adj_close(\n",
    "    ticker=ticker, \n",
    "    dates=dates, \n",
    "    close=df['Close'], \n",
    "    snr_values=df['SNR'],\n",
    "    window=window\n",
    ")\n",
    "\n",
    "# Plotando o scatter plot entre SNR e STD\n",
    "f_br.plot_snr_vs_returns(\n",
    "    snr_values=df['SNR'],\n",
    "    returns=df['STD']\n",
    ")\n",
    "\n",
    "# Sinais de trading com SNR\n",
    "df_trading = f_br.create_trading_signals(df=df, window=window)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.05, \n",
    "    subplot_titles=('Close', 'SNR')\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_trading.index,\n",
    "    y=df_trading['Close'],\n",
    "    mode='lines',\n",
    "    name='Close',\n",
    "    line=dict(color='blue')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_trading.index,\n",
    "    y=df_trading['SNR'],\n",
    "    mode='lines',\n",
    "    name='SNR',\n",
    "    line=dict(color='red')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Adicionando os sinais de compra e venda no gráfico de preço\n",
    "buy_signals = df[df['Signal'] == 1]\n",
    "sell_signals = df[df['Signal'] == -1]\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=buy_signals.index,\n",
    "    y=buy_signals['Close'],\n",
    "    mode='markers',\n",
    "    name='Buy Signal',\n",
    "    marker=dict(color='green', size=10, symbol='triangle-up')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sell_signals.index,\n",
    "    y=sell_signals['Close'],\n",
    "    mode='markers',\n",
    "    name='Sell Signal',\n",
    "    marker=dict(color='red', size=10, symbol='triangle-down')),\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=ticker + ' - Close e SNR com Sinais de Trading',\n",
    "    height=1500,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='Data', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Close', row=1, col=1)\n",
    "fig.update_yaxes(title_text='SNR (dB)', row=1, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Divergência no Índice de Força Relativa (IFR ou RSI)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vídeo da aula: https://www.youtube.com/watch?v=ISWfUqXc5EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = '^BVSP'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2025-12-31'\n",
    "\n",
    "df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=True, multi_level_index=False)['Close']\n",
    "df = df.reset_index()\n",
    "df.columns = ['Date', 'Close']\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Calculando o RSI\n",
    "df['RSI'] = f_br.calculate_rsi(df=df['Close'], window=14)\n",
    "\n",
    "# Detectando as divergências\n",
    "divergences = f_br.detect_rsi_divergence(df=df['Close'], rsi=df['RSI'], lookback=14)\n",
    "\n",
    "# Exibindo as divergências encontradas\n",
    "print('Divergências encontradas:')\n",
    "print(divergences.tail())\n",
    "\n",
    "# Plotando o gráfico\n",
    "f_br.plot_rsi_divergence(df=df['Close'], rsi=df['RSI'], divergences=divergences, symbol=symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'QQQ'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2025-12-31'\n",
    "\n",
    "df = yf.download(symbol, start=start_date, end=end_date, auto_adjust=True, multi_level_index=False)['Close']\n",
    "df = df.reset_index()\n",
    "df.columns = ['Date', 'Close']\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Calculando o RSI\n",
    "df['RSI'] = f_br.calculate_rsi(df=df['Close'], window=14)\n",
    "\n",
    "# Detectando as divergências\n",
    "divergences = f_br.detect_rsi_divergence(df=df['Close'], rsi=df['RSI'], lookback=14)\n",
    "\n",
    "# Exibindo as divergências encontradas\n",
    "print('Divergências encontradas:')\n",
    "print(divergences.tail())\n",
    "\n",
    "# Plotando o gráfico\n",
    "f_br.plot_rsi_divergence(df=df['Close'], rsi=df['RSI'], divergences=divergences, symbol=symbol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
